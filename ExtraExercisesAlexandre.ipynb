{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The head of the dataset is -\n",
      "  date_chargement date validation                statut_dossier  \\\n",
      "0      2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "1      2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "2      2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "3      2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "4      2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "\n",
      "  type_referentiel type_formation2  code_rs  code_rncp  \\\n",
      "0             RNCP             NaN       -1      34029   \n",
      "1            Autre           Autre       -1         -1   \n",
      "2            Autre           Autre       -1         -1   \n",
      "3            Autre           Autre       -1         -1   \n",
      "4            Autre           Autre       -1         -1   \n",
      "\n",
      "                               domaine_formation_nsf  formacode_principal  \\\n",
      "0  Spécialités plurivalentes des échanges et de l...                  NaN   \n",
      "1  Developpement des capacités d orientation,d in...              15081.0   \n",
      "2  Developpement des capacités d orientation,d in...              15081.0   \n",
      "3  Developpement des capacités d orientation,d in...              15064.0   \n",
      "4  Developpement des capacités d orientation,d in...              15064.0   \n",
      "\n",
      "  libelle_formacode_principal  ... part_cec Code Officiel Département  \\\n",
      "0                         NaN  ...        0                       NaN   \n",
      "1         Bilan professionnel  ...        0                        50   \n",
      "2         Bilan professionnel  ...        0                        81   \n",
      "3             Préparation VAE  ...        0                        64   \n",
      "4             Préparation VAE  ...        0                        14   \n",
      "\n",
      "  Code Officiel Région  Nom Officiel Département Majuscule  \\\n",
      "0                  NaN                                 NaN   \n",
      "1                 28.0                              MANCHE   \n",
      "2                 76.0                                TARN   \n",
      "3                 75.0                PYRENEES ATLANTIQUES   \n",
      "4                 28.0                            CALVADOS   \n",
      "\n",
      "   année de validation  code_certifinfo              intitule_certification  \\\n",
      "0                 2022         100365.0  BTS Support à l'action managériale   \n",
      "1                 2022          93559.0                Bilan de compétences   \n",
      "2                 2022          93559.0                Bilan de compétences   \n",
      "3                 2022          83899.0                  Accompagnement VAE   \n",
      "4                 2022          83899.0                  Accompagnement VAE   \n",
      "\n",
      "   code_region_lieu_formation  code_postal_lieu_formation  Mois de validation  \n",
      "0                          NC                          NC                   7  \n",
      "1                          28                       50200                   7  \n",
      "2                          76                       81000                   7  \n",
      "3                          75                       64000                   7  \n",
      "4                          28                       14000                   7  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['date_chargement', 'date validation', 'statut_dossier',\n",
       "       'type_referentiel', 'type_formation2', 'code_rs', 'code_rncp',\n",
       "       'domaine_formation_nsf', 'formacode_principal',\n",
       "       'libelle_formacode_principal', 'modalite_presence',\n",
       "       'region_lieu_formation', 'departement_lieu_formation', 'nb_dossiers',\n",
       "       'nb_titulaires', 'prix_moyen', 'nb_dossiers_a_duree_connue',\n",
       "       'duree_moyenne', 'montant_engage', 'part_france_competences',\n",
       "       'nb_dossiers_finances_par_titulaires', 'part_titulaire',\n",
       "       'nb_dossiers_finances_par_etat', 'part_etat',\n",
       "       'nb_dossiers_finances_par_pole_emploi', 'part_pole_emploi',\n",
       "       'nb_dossiers_finances_par_regions', 'part_region',\n",
       "       'nb_dossiers_finances_par_opco', 'part_opco',\n",
       "       'nb_dossiers_finances_par_entreprises', 'part_entreprise',\n",
       "       'nb_dossiers_finances_par_cec', 'part_cec', 'Code Officiel Département',\n",
       "       'Code Officiel Région', 'Nom Officiel Département Majuscule',\n",
       "       'année de validation', 'code_certifinfo', 'intitule_certification',\n",
       "       'code_region_lieu_formation', 'code_postal_lieu_formation',\n",
       "       'Mois de validation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\CYTech Student\\\\moncompteformation_formations_engagees.csv\", header=0, delimiter=\";\")\n",
    "print(\"The head of the dataset is -\")\n",
    "print(data.head())\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Lambda and functions - Explain what lambda is used for when applying it to functions in Python. Apply\n",
    "the lambda approach to the application of functions to replace values in\n",
    "”Formations engag´ees” - Nom du d´epartement - from ”Paris” to ”Capitale”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date_chargement date validation                statut_dossier  \\\n",
      "0            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "1            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "2            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "3            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "4            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "...                 ...             ...                           ...   \n",
      "1387008      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "1387009      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "1387010      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "1387011      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "1387012      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "\n",
      "        type_referentiel type_formation2  code_rs  code_rncp  \\\n",
      "0                   RNCP             NaN       -1      34029   \n",
      "1                  Autre           Autre       -1         -1   \n",
      "2                  Autre           Autre       -1         -1   \n",
      "3                  Autre           Autre       -1         -1   \n",
      "4                  Autre           Autre       -1         -1   \n",
      "...                  ...             ...      ...        ...   \n",
      "1387008             RNCP             NaN       -1      35288   \n",
      "1387009             RNCP             NaN       -1      36112   \n",
      "1387010             RNCP             NaN       -1      35228   \n",
      "1387011             RNCP             NaN       -1      35228   \n",
      "1387012             RNCP             NaN       -1      34545   \n",
      "\n",
      "                                     domaine_formation_nsf  \\\n",
      "0        Spécialités plurivalentes des échanges et de l...   \n",
      "1        Developpement des capacités d orientation,d in...   \n",
      "2        Developpement des capacités d orientation,d in...   \n",
      "3        Developpement des capacités d orientation,d in...   \n",
      "4        Developpement des capacités d orientation,d in...   \n",
      "...                                                    ...   \n",
      "1387008  Informatique, traitement de l'information, rés...   \n",
      "1387009                Travail du bois et de l'ameublement   \n",
      "1387010                   Habillement (y.c. mode, couture)   \n",
      "1387011                   Habillement (y.c. mode, couture)   \n",
      "1387012  Informatique, traitement de l'information, rés...   \n",
      "\n",
      "         formacode_principal  \\\n",
      "0                        NaN   \n",
      "1                    15081.0   \n",
      "2                    15081.0   \n",
      "3                    15064.0   \n",
      "4                    15064.0   \n",
      "...                      ...   \n",
      "1387008                  NaN   \n",
      "1387009                  NaN   \n",
      "1387010                  NaN   \n",
      "1387011                  NaN   \n",
      "1387012              31026.0   \n",
      "\n",
      "                               libelle_formacode_principal  ... part_cec  \\\n",
      "0                                                      NaN  ...        0   \n",
      "1                                      Bilan professionnel  ...        0   \n",
      "2                                      Bilan professionnel  ...        0   \n",
      "3                                          Préparation VAE  ...        0   \n",
      "4                                          Préparation VAE  ...        0   \n",
      "...                                                    ...  ...      ...   \n",
      "1387008  Intelligence artificielle|Mathématiques appliq...  ...        0   \n",
      "1387009  Ameublement|Menuiserie bois|Menuiserie agencement  ...        0   \n",
      "1387010  Essayage retouche|Couture|Vêtement|Vêtement fé...  ...        0   \n",
      "1387011  Essayage retouche|Couture|Vêtement|Vêtement fé...  ...        0   \n",
      "1387012                                       Data science  ...        0   \n",
      "\n",
      "        Code Officiel Département Code Officiel Région  \\\n",
      "0                             NaN                  NaN   \n",
      "1                              50                 28.0   \n",
      "2                              81                 76.0   \n",
      "3                              64                 75.0   \n",
      "4                              14                 28.0   \n",
      "...                           ...                  ...   \n",
      "1387008                        69                 84.0   \n",
      "1387009                        13                 93.0   \n",
      "1387010                        44                 52.0   \n",
      "1387011                        81                 76.0   \n",
      "1387012                       NaN                  NaN   \n",
      "\n",
      "         Nom Officiel Département Majuscule  année de validation  \\\n",
      "0                                       nan                 2022   \n",
      "1                                    MANCHE                 2022   \n",
      "2                                      TARN                 2022   \n",
      "3                      PYRENEES ATLANTIQUES                 2022   \n",
      "4                                  CALVADOS                 2022   \n",
      "...                                     ...                  ...   \n",
      "1387008                               RHONE                 2022   \n",
      "1387009                    BOUCHES DU RHONE                 2022   \n",
      "1387010                    LOIRE ATLANTIQUE                 2022   \n",
      "1387011                                TARN                 2022   \n",
      "1387012                                 nan                 2022   \n",
      "\n",
      "         code_certifinfo                         intitule_certification  \\\n",
      "0               100365.0             BTS Support à l'action managériale   \n",
      "1                93559.0                           Bilan de compétences   \n",
      "2                93559.0                           Bilan de compétences   \n",
      "3                83899.0                             Accompagnement VAE   \n",
      "4                83899.0                             Accompagnement VAE   \n",
      "...                  ...                                            ...   \n",
      "1387008         110593.0  Concepteur développeur en science des données   \n",
      "1387009         110405.0                        CAP Menuisier fabricant   \n",
      "1387010         110271.0                        TP Couturier retoucheur   \n",
      "1387011         110271.0                        TP Couturier retoucheur   \n",
      "1387012         108013.0                                 Data scientist   \n",
      "\n",
      "         code_region_lieu_formation  code_postal_lieu_formation  \\\n",
      "0                                NC                          NC   \n",
      "1                                28                       50200   \n",
      "2                                76                       81000   \n",
      "3                                75                       64000   \n",
      "4                                28                       14000   \n",
      "...                             ...                         ...   \n",
      "1387008                          84                       69002   \n",
      "1387009                          93                       13014   \n",
      "1387010                          52                       44100   \n",
      "1387011                          76                       81310   \n",
      "1387012                          NC                          NC   \n",
      "\n",
      "         Mois de validation  \n",
      "0                         7  \n",
      "1                         7  \n",
      "2                         7  \n",
      "3                         7  \n",
      "4                         7  \n",
      "...                     ...  \n",
      "1387008                  12  \n",
      "1387009                  12  \n",
      "1387010                  12  \n",
      "1387011                  12  \n",
      "1387012                  12  \n",
      "\n",
      "[1387013 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "data[\"Nom Officiel Département Majuscule\"] = data[\"Nom Officiel Département Majuscule\"].apply(lambda x: str(x).replace('Paris','Capitale'))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Pandas options - Change the options within pandas to change the number of decimals that would\n",
    "be displayed when you print numbers. It should start like that : pd.set option(...).\n",
    "Display an example to show that your code works, once with one decimal, once\n",
    "with two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with one decimal:\n",
      "   Value\n",
      "0    3.1\n",
      "1    2.7\n",
      "2   42.1\n",
      "\n",
      "DataFrame with two decimals:\n",
      "   Value\n",
      "0   3.14\n",
      "1   2.72\n",
      "2  42.12\n"
     ]
    }
   ],
   "source": [
    "#For one decimal\n",
    "pd.set_option('display.float_format', '{:.1f}'.format)\n",
    "\n",
    "data3 = {'Value': [3.14159, 2.71828, 42.12345]}\n",
    "df = pd.DataFrame(data3)\n",
    "\n",
    "#One decimal print\n",
    "print(\"DataFrame with one decimal:\")\n",
    "print(df)\n",
    "\n",
    "#For two decimals\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "#two decimals print\n",
    "print(\"\\nDataFrame with two decimals:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 select dtypes - Use the CPF dataset for this one. dtype has include and exclude parameters\n",
    "that you can use to select columns including or excluding certain data types.\n",
    "After having turned the year date into a date format, apply dtype to select only\n",
    "column with dates, and once more to exclude such a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with datetime data type:\n",
      "                  année de validation\n",
      "0       1970-01-01 00:00:00.000002022\n",
      "1       1970-01-01 00:00:00.000002022\n",
      "2       1970-01-01 00:00:00.000002022\n",
      "3       1970-01-01 00:00:00.000002022\n",
      "4       1970-01-01 00:00:00.000002022\n",
      "...                               ...\n",
      "1387008 1970-01-01 00:00:00.000002022\n",
      "1387009 1970-01-01 00:00:00.000002022\n",
      "1387010 1970-01-01 00:00:00.000002022\n",
      "1387011 1970-01-01 00:00:00.000002022\n",
      "1387012 1970-01-01 00:00:00.000002022\n",
      "\n",
      "[1387013 rows x 1 columns]\n",
      "Columns excluding datetime data type:\n",
      "        date_chargement date validation                statut_dossier  \\\n",
      "0            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "1            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "2            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "3            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "4            2023-12-01         2022-07  Clos - Réalisation Partielle   \n",
      "...                 ...             ...                           ...   \n",
      "1387008      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "1387009      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "1387010      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "1387011      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "1387012      2023-12-01         2022-12     Clos - Réalisation Totale   \n",
      "\n",
      "        type_referentiel type_formation2  code_rs  code_rncp  \\\n",
      "0                   RNCP             NaN       -1      34029   \n",
      "1                  Autre           Autre       -1         -1   \n",
      "2                  Autre           Autre       -1         -1   \n",
      "3                  Autre           Autre       -1         -1   \n",
      "4                  Autre           Autre       -1         -1   \n",
      "...                  ...             ...      ...        ...   \n",
      "1387008             RNCP             NaN       -1      35288   \n",
      "1387009             RNCP             NaN       -1      36112   \n",
      "1387010             RNCP             NaN       -1      35228   \n",
      "1387011             RNCP             NaN       -1      35228   \n",
      "1387012             RNCP             NaN       -1      34545   \n",
      "\n",
      "                                     domaine_formation_nsf  \\\n",
      "0        Spécialités plurivalentes des échanges et de l...   \n",
      "1        Developpement des capacités d orientation,d in...   \n",
      "2        Developpement des capacités d orientation,d in...   \n",
      "3        Developpement des capacités d orientation,d in...   \n",
      "4        Developpement des capacités d orientation,d in...   \n",
      "...                                                    ...   \n",
      "1387008  Informatique, traitement de l'information, rés...   \n",
      "1387009                Travail du bois et de l'ameublement   \n",
      "1387010                   Habillement (y.c. mode, couture)   \n",
      "1387011                   Habillement (y.c. mode, couture)   \n",
      "1387012  Informatique, traitement de l'information, rés...   \n",
      "\n",
      "         formacode_principal  \\\n",
      "0                        NaN   \n",
      "1                   15081.00   \n",
      "2                   15081.00   \n",
      "3                   15064.00   \n",
      "4                   15064.00   \n",
      "...                      ...   \n",
      "1387008                  NaN   \n",
      "1387009                  NaN   \n",
      "1387010                  NaN   \n",
      "1387011                  NaN   \n",
      "1387012             31026.00   \n",
      "\n",
      "                               libelle_formacode_principal  ...  \\\n",
      "0                                                      NaN  ...   \n",
      "1                                      Bilan professionnel  ...   \n",
      "2                                      Bilan professionnel  ...   \n",
      "3                                          Préparation VAE  ...   \n",
      "4                                          Préparation VAE  ...   \n",
      "...                                                    ...  ...   \n",
      "1387008  Intelligence artificielle|Mathématiques appliq...  ...   \n",
      "1387009  Ameublement|Menuiserie bois|Menuiserie agencement  ...   \n",
      "1387010  Essayage retouche|Couture|Vêtement|Vêtement fé...  ...   \n",
      "1387011  Essayage retouche|Couture|Vêtement|Vêtement fé...  ...   \n",
      "1387012                                       Data science  ...   \n",
      "\n",
      "        nb_dossiers_finances_par_cec part_cec Code Officiel Département  \\\n",
      "0                                  0        0                       NaN   \n",
      "1                                  0        0                        50   \n",
      "2                                  0        0                        81   \n",
      "3                                  0        0                        64   \n",
      "4                                  0        0                        14   \n",
      "...                              ...      ...                       ...   \n",
      "1387008                            0        0                        69   \n",
      "1387009                            0        0                        13   \n",
      "1387010                            0        0                        44   \n",
      "1387011                            0        0                        81   \n",
      "1387012                            0        0                       NaN   \n",
      "\n",
      "         Code Officiel Région  Nom Officiel Département Majuscule  \\\n",
      "0                         NaN                                 nan   \n",
      "1                       28.00                              MANCHE   \n",
      "2                       76.00                                TARN   \n",
      "3                       75.00                PYRENEES ATLANTIQUES   \n",
      "4                       28.00                            CALVADOS   \n",
      "...                       ...                                 ...   \n",
      "1387008                 84.00                               RHONE   \n",
      "1387009                 93.00                    BOUCHES DU RHONE   \n",
      "1387010                 52.00                    LOIRE ATLANTIQUE   \n",
      "1387011                 76.00                                TARN   \n",
      "1387012                   NaN                                 nan   \n",
      "\n",
      "         code_certifinfo                         intitule_certification  \\\n",
      "0              100365.00             BTS Support à l'action managériale   \n",
      "1               93559.00                           Bilan de compétences   \n",
      "2               93559.00                           Bilan de compétences   \n",
      "3               83899.00                             Accompagnement VAE   \n",
      "4               83899.00                             Accompagnement VAE   \n",
      "...                  ...                                            ...   \n",
      "1387008        110593.00  Concepteur développeur en science des données   \n",
      "1387009        110405.00                        CAP Menuisier fabricant   \n",
      "1387010        110271.00                        TP Couturier retoucheur   \n",
      "1387011        110271.00                        TP Couturier retoucheur   \n",
      "1387012        108013.00                                 Data scientist   \n",
      "\n",
      "         code_region_lieu_formation  code_postal_lieu_formation  \\\n",
      "0                                NC                          NC   \n",
      "1                                28                       50200   \n",
      "2                                76                       81000   \n",
      "3                                75                       64000   \n",
      "4                                28                       14000   \n",
      "...                             ...                         ...   \n",
      "1387008                          84                       69002   \n",
      "1387009                          93                       13014   \n",
      "1387010                          52                       44100   \n",
      "1387011                          76                       81310   \n",
      "1387012                          NC                          NC   \n",
      "\n",
      "         Mois de validation  \n",
      "0                         7  \n",
      "1                         7  \n",
      "2                         7  \n",
      "3                         7  \n",
      "4                         7  \n",
      "...                     ...  \n",
      "1387008                  12  \n",
      "1387009                  12  \n",
      "1387010                  12  \n",
      "1387011                  12  \n",
      "1387012                  12  \n",
      "\n",
      "[1387013 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "data['année de validation'] = pd.to_datetime(data['année de validation'])\n",
    "\n",
    "# Select only columns with datetime data type\n",
    "date_columns = data.select_dtypes(include='datetime64[ns]')\n",
    "print(\"Columns with datetime data type:\")\n",
    "print(date_columns)\n",
    "\n",
    "# Exclude columns with datetime data type\n",
    "non_date_columns = data.select_dtypes(exclude='datetime64[ns]')\n",
    "print(\"Columns excluding datetime data type:\")\n",
    "print(non_date_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Clip - Create a dataframe with one column (name : col) and 15 rows. Fill these rows\n",
    "with integers randomingly taken from the 10 to 50 interval. Clip the data at 20\n",
    "(lower limit) and 30 (upper limit) and print the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    col\n",
      "0    24\n",
      "1    20\n",
      "2    30\n",
      "3    28\n",
      "4    20\n",
      "5    30\n",
      "6    20\n",
      "7    20\n",
      "8    30\n",
      "9    30\n",
      "10   30\n",
      "11   30\n",
      "12   23\n",
      "13   30\n",
      "14   30\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'col': np.random.randint(10, 51, size=15)})\n",
    "df['col'] = df['col'].clip(lower=20, upper=30)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 between time - Create a time series of events encompassing an entire day, separated by 10 minutes,\n",
    "and use the between time function to select events that occurred between\n",
    "09h40 and 12h20. Print the results (head only, 10 entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     event\n",
      "2023-01-01 09:40:00     58\n",
      "2023-01-01 09:50:00     59\n",
      "2023-01-01 10:00:00     60\n",
      "2023-01-01 10:10:00     61\n",
      "2023-01-01 10:20:00     62\n",
      "2023-01-01 10:30:00     63\n",
      "2023-01-01 10:40:00     64\n",
      "2023-01-01 10:50:00     65\n",
      "2023-01-01 11:00:00     66\n",
      "2023-01-01 11:10:00     67\n"
     ]
    }
   ],
   "source": [
    "start_time = '2023-01-01 00:00:00'\n",
    "end_time = '2023-01-01 23:50:00'\n",
    "time_index = pd.date_range(start=start_time, end=end_time, freq='10T')\n",
    "events = pd.DataFrame({'event': np.arange(len(time_index))}, index=time_index)\n",
    "\n",
    "selected_events = events.between_time('09:40', '12:20')\n",
    "\n",
    "print(selected_events.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 time, missing values - You will use the Melbourne Housing dataset melb house.csv\n",
    "1. During the import phase, do not read all the columns, but subset the\n",
    "raw data by using usecols. Focus on the following variables : ”Suburb”,\n",
    "”Date”, ”Type”, ”Regionname”, ”Distance”, ”Price”\n",
    "2. Count the number of missing values per column\n",
    "3. Drop the missing values\n",
    "4. Create a column that shows the price in millions. It can be calculated\n",
    "simply by dividing the price column with 1 million.\n",
    "5. The new column is added at the end of the data frame. Using insert,\n",
    "insert it next to the price column.\n",
    "6. Encode categorical (of variable ”type”)\n",
    "7. Count the number of unique Region names\n",
    "8. Extract the year and month from the date\n",
    "9. Use the rank function to provide a ranking of the prices\n",
    "10. Sort values according to this ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values per column:\n",
      " suburb            0\n",
      "type              0\n",
      "price          7610\n",
      "date              0\n",
      "distance          1\n",
      "region_name       3\n",
      "dtype: int64\n",
      "Number of unique Region names: 8\n",
      "The result for the new data set is:             suburb       price        date  distance  \\\n",
      "25635    Brighton 11200000.00  2017-10-28     10.50   \n",
      "19583    Mulgrave  9000000.00  2017-07-29     18.80   \n",
      "12539  Canterbury  8000000.00  2017-05-13      9.00   \n",
      "15696    Hawthorn  7650000.00  2017-06-17      5.30   \n",
      "28334    Armadale  7000000.00  2017-11-25      6.30   \n",
      "\n",
      "                      region_name  price_millions  type_t  type_u  year  \\\n",
      "25635       Southern Metropolitan           11.20   False   False  2017   \n",
      "19583  South-Eastern Metropolitan            9.00   False   False  2017   \n",
      "12539       Southern Metropolitan            8.00   False   False  2017   \n",
      "15696       Southern Metropolitan            7.65   False   False  2017   \n",
      "28334       Southern Metropolitan            7.00   False   False  2017   \n",
      "\n",
      "       month  price_rank  \n",
      "25635     10        1.00  \n",
      "19583      7        2.00  \n",
      "12539      5        3.00  \n",
      "15696      6        4.00  \n",
      "28334     11        5.00  \n"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"H:\\Downloads\\melb_house.csv\", header=0, delimiter=\",\")\n",
    "\n",
    "#1. Importing data with subset of columns\n",
    "selected_columns = ['suburb', 'date', 'type', 'region_name', 'distance', 'price']\n",
    "melb_house_data = pd.read_csv(\"H:\\Downloads\\melb_house.csv\", usecols=selected_columns)\n",
    "\n",
    "#2. Count the number of missing values per column\n",
    "missing_values_count = melb_house_data.isnull().sum()\n",
    "print(\"Number of missing values per column:\\n\", missing_values_count)\n",
    "\n",
    "#3. Drop the missing values\n",
    "melb_house_data = melb_house_data.dropna()\n",
    "\n",
    "#4.Create a column that shows the price in millions. It can be calculated simply by dividing the price column with 1 million.\n",
    "melb_house_data['price_millions'] = melb_house_data['price'] / 1_000_000\n",
    "\n",
    "#5. The new column is added at the end of the data frame. Using insert,insert it next to the price column\n",
    "if 'price_millions' not in melb_house_data.columns:\n",
    "    melb_house_data.insert(melb_house_data.columns.get_loc('price') + 1, 'price_millions', melb_house_data['price'] / 1_000_000)\n",
    "\n",
    "\n",
    "#6. Encode categorical (of variable ”type”)\n",
    "melb_house_data = pd.get_dummies(melb_house_data, columns=['type'], prefix='type', drop_first=True)\n",
    "\n",
    "#7. Count the number of unique Region names\n",
    "unique_region_names = melb_house_data['region_name'].nunique()\n",
    "print(\"Number of unique Region names:\", unique_region_names)\n",
    "\n",
    "#8.) Extract the year and month from the date\n",
    "melb_house_data['year'] = pd.to_datetime(melb_house_data['date']).dt.year\n",
    "melb_house_data['month'] = pd.to_datetime(melb_house_data['date']).dt.month\n",
    "\n",
    "#9.) Use the rank function to provide a ranking of the prices\n",
    "\n",
    "melb_house_data['price_rank'] = melb_house_data['price'].rank(ascending=False)\n",
    "\n",
    "#10.) Sort values according to this ranking\n",
    "melb_house_data_sorted = melb_house_data.sort_values(by='price_rank')\n",
    "\n",
    "#Result\n",
    "print(\"The result for the new data set is: \", melb_house_data_sorted.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7 Rolling window - Use the ”apple” dataset to apply a rolling window where you compute the mean\n",
    "value for all columns from ”close” to ”low”. Provide a print of the head (10\n",
    "entries) of your newly created datasets for two different window sizez (3 and 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of the dataset with window size 3:\n",
      "\n",
      "         date  close      volume   open   high    low\n",
      "0       16:00    NaN         NaN    NaN    NaN    NaN\n",
      "1  2018/11/13    NaN         NaN    NaN    NaN    NaN\n",
      "2  2018/11/12 192.88 48086061.33 194.12 198.07 192.23\n",
      "3  2018/11/09 196.96 44011500.00 198.73 201.01 195.83\n",
      "4  2018/11/08 202.38 36866020.00 204.84 205.33 200.93\n",
      "5  2018/11/07 207.64 30966223.33 207.17 208.73 204.38\n",
      "6  2018/11/06 207.40 30118543.33 205.96 208.30 204.19\n",
      "7  2018/11/05 205.10 43712843.33 204.06 206.39 201.33\n",
      "8  2018/11/02 204.28 62964483.33 205.26 207.59 201.76\n",
      "9  2018/11/01 210.43 70024266.67 210.97 213.47 206.80\n",
      "\n",
      "Head of the dataset with window size 5:\n",
      "\n",
      "         date  close      volume   open   high    low\n",
      "0       16:00    NaN         NaN    NaN    NaN    NaN\n",
      "1  2018/11/13    NaN         NaN    NaN    NaN    NaN\n",
      "2  2018/11/12    NaN         NaN    NaN    NaN    NaN\n",
      "3  2018/11/09    NaN         NaN    NaN    NaN    NaN\n",
      "4  2018/11/08 198.32 40773042.80 199.58 202.07 197.14\n",
      "5  2018/11/07 201.86 38123082.00 202.43 204.64 199.67\n",
      "6  2018/11/06 204.17 35132884.00 204.48 206.15 201.72\n",
      "7  2018/11/05 205.65 38149112.00 205.54 207.06 202.60\n",
      "8  2018/11/02 206.26 49494872.00 206.34 208.59 203.23\n",
      "9  2018/11/01 209.00 55027832.00 208.16 211.04 205.25\n"
     ]
    }
   ],
   "source": [
    "#reading apple csv\n",
    "data3 = pd.read_csv(\"H:\\\\Downloads\\\\apple.csv\", header=0, delimiter=\",\")\n",
    "\n",
    "coltoavg = ['close', 'volume', 'open', 'high', 'low']\n",
    "\n",
    "#Setting the window sizes for 3 and 5\n",
    "windowsizes = [3, 5]\n",
    "\n",
    "data3['volume'] = pd.to_numeric(data3['volume'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "#Creating a new DataFrame for each window size\n",
    "for window_size in windowsizes:\n",
    "    #Rolling mean to the specified columns\n",
    "    rollingmean = data3[coltoavg].rolling(window=window_size).mean()\n",
    "\n",
    "    #Combine the rolling mean with the date column\n",
    "    result = pd.concat([data3['date'], rollingmean], axis=1)\n",
    "\n",
    "    #Result\n",
    "    print(f\"\\nHead of the dataset with window size {window_size}:\\n\")\n",
    "    print(result.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8 Combine describe with transpose (T) - Use the ”describe” function to describe the ”apple” dataset, and then transpose\n",
    "the summary using T.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed summary statistics:\n",
      "       count   mean   std    min    25%    50%    75%    max\n",
      "close 254.00 189.08 20.00 155.15 172.80 185.43 207.52 232.07\n",
      "open  254.00 189.02 19.98 154.83 172.87 185.24 207.22 230.78\n",
      "high  254.00 190.80 20.22 157.89 174.27 187.13 209.21 233.47\n",
      "low   254.00 187.38 19.69 150.24 171.79 183.92 205.47 229.78\n"
     ]
    }
   ],
   "source": [
    "#Using describe() \n",
    "summary_stats = data3.describe()\n",
    "\n",
    "#Transpose code\n",
    "transposed_summary = summary_stats.T\n",
    "\n",
    "#Result\n",
    "print(\"Transposed summary statistics:\")\n",
    "print(transposed_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9 Add a style to your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap for the 'close' column:\n",
      "\n",
      "DataFrame with Min and Max Values Highlighted:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_df365_row0_col0, #T_df365_row0_col3, #T_df365_row0_col4, #T_df365_row1_col0, #T_df365_row1_col2, #T_df365_row1_col3, #T_df365_row1_col4, #T_df365_row4_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_df365_row8_col1, #T_df365_row15_col2, #T_df365_row15_col3, #T_df365_row16_col0, #T_df365_row17_col4 {\n",
       "  background-color: lightcoral;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_df365\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_df365_level0_col0\" class=\"col_heading level0 col0\" >close</th>\n",
       "      <th id=\"T_df365_level0_col1\" class=\"col_heading level0 col1\" >volume</th>\n",
       "      <th id=\"T_df365_level0_col2\" class=\"col_heading level0 col2\" >open</th>\n",
       "      <th id=\"T_df365_level0_col3\" class=\"col_heading level0 col3\" >high</th>\n",
       "      <th id=\"T_df365_level0_col4\" class=\"col_heading level0 col4\" >low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_df365_row0_col0\" class=\"data row0 col0\" >192.230000</td>\n",
       "      <td id=\"T_df365_row0_col1\" class=\"data row0 col1\" >46,541,444</td>\n",
       "      <td id=\"T_df365_row0_col2\" class=\"data row0 col2\" >191.720000</td>\n",
       "      <td id=\"T_df365_row0_col3\" class=\"data row0 col3\" >197.180000</td>\n",
       "      <td id=\"T_df365_row0_col4\" class=\"data row0 col4\" >191.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_df365_row1_col0\" class=\"data row1 col0\" >192.230000</td>\n",
       "      <td id=\"T_df365_row1_col1\" class=\"data row1 col1\" >46725710.0000</td>\n",
       "      <td id=\"T_df365_row1_col2\" class=\"data row1 col2\" >191.630000</td>\n",
       "      <td id=\"T_df365_row1_col3\" class=\"data row1 col3\" >197.180000</td>\n",
       "      <td id=\"T_df365_row1_col4\" class=\"data row1 col4\" >191.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_df365_row2_col0\" class=\"data row2 col0\" >194.170000</td>\n",
       "      <td id=\"T_df365_row2_col1\" class=\"data row2 col1\" >50991030.0000</td>\n",
       "      <td id=\"T_df365_row2_col2\" class=\"data row2 col2\" >199.000000</td>\n",
       "      <td id=\"T_df365_row2_col3\" class=\"data row2 col3\" >199.850000</td>\n",
       "      <td id=\"T_df365_row2_col4\" class=\"data row2 col4\" >193.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_df365_row3_col0\" class=\"data row3 col0\" >204.470000</td>\n",
       "      <td id=\"T_df365_row3_col1\" class=\"data row3 col1\" >34317760.0000</td>\n",
       "      <td id=\"T_df365_row3_col2\" class=\"data row3 col2\" >205.550000</td>\n",
       "      <td id=\"T_df365_row3_col3\" class=\"data row3 col3\" >206.010000</td>\n",
       "      <td id=\"T_df365_row3_col4\" class=\"data row3 col4\" >202.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_df365_row4_col0\" class=\"data row4 col0\" >208.490000</td>\n",
       "      <td id=\"T_df365_row4_col1\" class=\"data row4 col1\" >25289270.0000</td>\n",
       "      <td id=\"T_df365_row4_col2\" class=\"data row4 col2\" >209.980000</td>\n",
       "      <td id=\"T_df365_row4_col3\" class=\"data row4 col3\" >210.120000</td>\n",
       "      <td id=\"T_df365_row4_col4\" class=\"data row4 col4\" >206.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_df365_row5_col0\" class=\"data row5 col0\" >209.950000</td>\n",
       "      <td id=\"T_df365_row5_col1\" class=\"data row5 col1\" >33291640.0000</td>\n",
       "      <td id=\"T_df365_row5_col2\" class=\"data row5 col2\" >205.970000</td>\n",
       "      <td id=\"T_df365_row5_col3\" class=\"data row5 col3\" >210.060000</td>\n",
       "      <td id=\"T_df365_row5_col4\" class=\"data row5 col4\" >204.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_df365_row6_col0\" class=\"data row6 col0\" >203.770000</td>\n",
       "      <td id=\"T_df365_row6_col1\" class=\"data row6 col1\" >31774720.0000</td>\n",
       "      <td id=\"T_df365_row6_col2\" class=\"data row6 col2\" >201.920000</td>\n",
       "      <td id=\"T_df365_row6_col3\" class=\"data row6 col3\" >204.720000</td>\n",
       "      <td id=\"T_df365_row6_col4\" class=\"data row6 col4\" >201.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_df365_row7_col0\" class=\"data row7 col0\" >201.590000</td>\n",
       "      <td id=\"T_df365_row7_col1\" class=\"data row7 col1\" >66072170.0000</td>\n",
       "      <td id=\"T_df365_row7_col2\" class=\"data row7 col2\" >204.300000</td>\n",
       "      <td id=\"T_df365_row7_col3\" class=\"data row7 col3\" >204.390000</td>\n",
       "      <td id=\"T_df365_row7_col4\" class=\"data row7 col4\" >198.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_df365_row8_col0\" class=\"data row8 col0\" >207.480000</td>\n",
       "      <td id=\"T_df365_row8_col1\" class=\"data row8 col1\" >91046560.0000</td>\n",
       "      <td id=\"T_df365_row8_col2\" class=\"data row8 col2\" >209.550000</td>\n",
       "      <td id=\"T_df365_row8_col3\" class=\"data row8 col3\" >213.650000</td>\n",
       "      <td id=\"T_df365_row8_col4\" class=\"data row8 col4\" >205.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_df365_row9_col0\" class=\"data row9 col0\" >222.220000</td>\n",
       "      <td id=\"T_df365_row9_col1\" class=\"data row9 col1\" >52954070.0000</td>\n",
       "      <td id=\"T_df365_row9_col2\" class=\"data row9 col2\" >219.050000</td>\n",
       "      <td id=\"T_df365_row9_col3\" class=\"data row9 col3\" >222.360000</td>\n",
       "      <td id=\"T_df365_row9_col4\" class=\"data row9 col4\" >216.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_df365_row10_col0\" class=\"data row10 col0\" >218.860000</td>\n",
       "      <td id=\"T_df365_row10_col1\" class=\"data row10 col1\" >38016810.0000</td>\n",
       "      <td id=\"T_df365_row10_col2\" class=\"data row10 col2\" >216.880000</td>\n",
       "      <td id=\"T_df365_row10_col3\" class=\"data row10 col3\" >220.450000</td>\n",
       "      <td id=\"T_df365_row10_col4\" class=\"data row10 col4\" >216.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_df365_row11_col0\" class=\"data row11 col0\" >213.300000</td>\n",
       "      <td id=\"T_df365_row11_col1\" class=\"data row11 col1\" >36487930.0000</td>\n",
       "      <td id=\"T_df365_row11_col2\" class=\"data row11 col2\" >211.150000</td>\n",
       "      <td id=\"T_df365_row11_col3\" class=\"data row11 col3\" >215.180000</td>\n",
       "      <td id=\"T_df365_row11_col4\" class=\"data row11 col4\" >209.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_df365_row12_col0\" class=\"data row12 col0\" >212.240000</td>\n",
       "      <td id=\"T_df365_row12_col1\" class=\"data row12 col1\" >45713690.0000</td>\n",
       "      <td id=\"T_df365_row12_col2\" class=\"data row12 col2\" >219.190000</td>\n",
       "      <td id=\"T_df365_row12_col3\" class=\"data row12 col3\" >219.690000</td>\n",
       "      <td id=\"T_df365_row12_col4\" class=\"data row12 col4\" >206.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_df365_row13_col0\" class=\"data row13 col0\" >216.300000</td>\n",
       "      <td id=\"T_df365_row13_col1\" class=\"data row13 col1\" >47191700.0000</td>\n",
       "      <td id=\"T_df365_row13_col2\" class=\"data row13 col2\" >215.900000</td>\n",
       "      <td id=\"T_df365_row13_col3\" class=\"data row13 col3\" >220.190000</td>\n",
       "      <td id=\"T_df365_row13_col4\" class=\"data row13 col4\" >212.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_df365_row14_col0\" class=\"data row14 col0\" >219.800000</td>\n",
       "      <td id=\"T_df365_row14_col1\" class=\"data row14 col1\" >29027340.0000</td>\n",
       "      <td id=\"T_df365_row14_col2\" class=\"data row14 col2\" >217.710000</td>\n",
       "      <td id=\"T_df365_row14_col3\" class=\"data row14 col3\" >221.380000</td>\n",
       "      <td id=\"T_df365_row14_col4\" class=\"data row14 col4\" >216.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_df365_row15_col0\" class=\"data row15 col0\" >215.090000</td>\n",
       "      <td id=\"T_df365_row15_col1\" class=\"data row15 col1\" >39992120.0000</td>\n",
       "      <td id=\"T_df365_row15_col2\" class=\"data row15 col2\" >222.600000</td>\n",
       "      <td id=\"T_df365_row15_col3\" class=\"data row15 col3\" >224.230000</td>\n",
       "      <td id=\"T_df365_row15_col4\" class=\"data row15 col4\" >214.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_df365_row16_col0\" class=\"data row16 col0\" >222.730000</td>\n",
       "      <td id=\"T_df365_row16_col1\" class=\"data row16 col1\" >38681170.0000</td>\n",
       "      <td id=\"T_df365_row16_col2\" class=\"data row16 col2\" >215.830000</td>\n",
       "      <td id=\"T_df365_row16_col3\" class=\"data row16 col3\" >223.250000</td>\n",
       "      <td id=\"T_df365_row16_col4\" class=\"data row16 col4\" >214.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_df365_row17_col0\" class=\"data row17 col0\" >220.650000</td>\n",
       "      <td id=\"T_df365_row17_col1\" class=\"data row17 col1\" >28751540.0000</td>\n",
       "      <td id=\"T_df365_row17_col2\" class=\"data row17 col2\" >219.790000</td>\n",
       "      <td id=\"T_df365_row17_col3\" class=\"data row17 col3\" >223.360000</td>\n",
       "      <td id=\"T_df365_row17_col4\" class=\"data row17 col4\" >218.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_df365_row18_col0\" class=\"data row18 col0\" >219.310000</td>\n",
       "      <td id=\"T_df365_row18_col1\" class=\"data row18 col1\" >32874330.0000</td>\n",
       "      <td id=\"T_df365_row18_col2\" class=\"data row18 col2\" >218.060000</td>\n",
       "      <td id=\"T_df365_row18_col3\" class=\"data row18 col3\" >221.260000</td>\n",
       "      <td id=\"T_df365_row18_col4\" class=\"data row18 col4\" >217.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df365_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_df365_row19_col0\" class=\"data row19 col0\" >216.020000</td>\n",
       "      <td id=\"T_df365_row19_col1\" class=\"data row19 col1\" >32389280.0000</td>\n",
       "      <td id=\"T_df365_row19_col2\" class=\"data row19 col2\" >217.860000</td>\n",
       "      <td id=\"T_df365_row19_col3\" class=\"data row19 col3\" >219.740000</td>\n",
       "      <td id=\"T_df365_row19_col4\" class=\"data row19 col4\" >213.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16fc3f776a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subset of the first 20 lines\n",
    "subset_data = data3.head(20)\n",
    "\n",
    "#1. Create a heatmap for the column ”close” using df.style.background gradient\n",
    "heatmap_data = subset_data[['close']]\n",
    "\n",
    "#Color map for the heatmap\n",
    "cmap = sns.light_palette(\"navy\", as_cmap=True)\n",
    "\n",
    "#Apply the background gradient to the \"close\" column\n",
    "heatmap_styled = heatmap_data.style.background_gradient(cmap=cmap)\n",
    "\n",
    "#Printing the heatmap\n",
    "print(\"Heatmap for the 'close' column:\")\n",
    "heatmap_styled\n",
    "\n",
    "#2. Highlight the minimum and maximum values for each column (except dates), using, notably highlight min\n",
    "highlighted_data = subset_data.drop(columns=['date']).style.highlight_min(axis=0, color='lightgreen').highlight_max(axis=0, color='lightcoral')\n",
    "\n",
    "#Result with min and max values\n",
    "print(\"\\nDataFrame with Min and Max Values Highlighted:\")\n",
    "highlighted_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
